{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from urllib.request import urlopen\n",
    "import certifi\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import json\n",
    "import queue\n",
    "import threading\n",
    "\n",
    "import fundamentalanalysis as fa\n",
    "import fa_mods as famods\n",
    "import fa_utils\n",
    "\n",
    "with open('/home/craigc/.keys/financialmodelingprep.txt', 'r') as file:\n",
    "    api_key = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies = fa.available_companies(api_key)\n",
    "tradeable_companies = famods.tradable_companies(api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "exchanges = all_companies.groupby('exchangeShortName')['exchange'].agg('unique').reset_index().rename(columns={'exchangeShortName': 'short_name', 'unique': 'exchange'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "datestamp = datetime.now().strftime('%y%m%d')\n",
    "\n",
    "with open(f'../data/all_symbols_{datestamp}.pkl', 'wb') as file:\n",
    "    pickle.dump(all_companies, file)\n",
    "\n",
    "with open(f'../data/all_tradable_symbols_{datestamp}.pkl', 'wb') as file:\n",
    "    pickle.dump(tradeable_companies, file)\n",
    "\n",
    "with open(f'../data/exchanges_{datestamp}.pkl', 'wb') as file:\n",
    "    pickle.dump(exchanges, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num LSE companies: 6335\n",
      "num LSE stocks: 3877\n",
      "\n",
      "num NYSE companies: 4070\n",
      "num NYSE stocks: 3463\n",
      "\n",
      "num NASDAQ companies: 10249\n",
      "num NASDAQ stocks: 5916\n"
     ]
    }
   ],
   "source": [
    "lse_companies = all_companies[(all_companies.exchangeShortName == 'LSE')]\n",
    "nyse_companies = all_companies[(all_companies.exchangeShortName == 'NYSE')]\n",
    "nasdaq_companies = all_companies[(all_companies.exchangeShortName == 'NASDAQ')]\n",
    "\n",
    "lse_stocks = lse_companies[(lse_companies.type == 'stock')].reset_index().drop(['exchange', 'exchangeShortName', 'type', 'price'], axis=1)\n",
    "nyse_stocks = nyse_companies[(nyse_companies.type == 'stock')].reset_index().drop(['exchange', 'exchangeShortName', 'type', 'price'], axis=1)\n",
    "nasdaq_stocks = nasdaq_companies[(nasdaq_companies.type == 'stock')].reset_index().drop(['exchange', 'exchangeShortName', 'type', 'price'], axis=1)\n",
    "\n",
    "print(f\"num LSE companies: {len(lse_companies)}\")\n",
    "print(f\"num LSE stocks: {len(lse_stocks)}\")\n",
    "print()\n",
    "print(f\"num NYSE companies: {len(nyse_companies)}\")\n",
    "print(f\"num NYSE stocks: {len(nyse_stocks)}\")\n",
    "print()\n",
    "print(f\"num NASDAQ companies: {len(nasdaq_companies)}\")\n",
    "print(f\"num NASDAQ stocks: {len(nasdaq_stocks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_lock = threading.Lock()\n",
    "\n",
    "def get_exchange_data(exchange: str):\n",
    "    exchange_companies = all_companies[(all_companies.exchangeShortName == exchange)]\n",
    "    exchange_stocks = exchange_companies[(exchange_companies.type == 'stock')].reset_index().drop(['exchange', 'exchangeShortName', 'type', 'price'], axis=1)\n",
    "\n",
    "    symbols = exchange_stocks.symbol.tolist()\n",
    "    stock_data = {}\n",
    "    failed = []\n",
    "    num_stocks = len(symbols)\n",
    "    cnt = 0\n",
    "\n",
    "    symbol_queue = queue.Queue()\n",
    "    [symbol_queue.put(s) for s in symbols]\n",
    "    symbol_queue.qsize()\n",
    "\n",
    "    def worker():\n",
    "        nonlocal cnt\n",
    "        nonlocal stock_data\n",
    "        nonlocal failed\n",
    "        while True:\n",
    "            with thread_lock:\n",
    "                cnt += 1\n",
    "                symbol = symbol_queue.get()        \n",
    "                print(f'{exchange} [{cnt}/{num_stocks}]: getting {symbol} - f[{len(failed)}], s[{len(stock_data)}]')\n",
    "\n",
    "            if symbol in stock_data:\n",
    "                print(f\"Already have {symbol}, skipping\")\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                data = fa_utils.get_ticker_data(symbol, api_key)\n",
    "                stock_data[symbol] = data\n",
    "                print(f\"{symbol} SUCCESS\")\n",
    "            except:\n",
    "                print(f\"{symbol} FAILED\")\n",
    "                failed.append(symbol)\n",
    "\n",
    "            symbol_queue.task_done()\n",
    "\n",
    "    for x in range(4):\n",
    "        name = \"Thread_\" + str(x)\n",
    "        t = threading.Thread(name=name,target=worker, daemon=True).start()\n",
    "\n",
    "    symbol_queue.join()\n",
    "\n",
    "    print(len(failed))\n",
    "    print(len(stock_data))\n",
    "\n",
    "    with open(f'../data/all_{exchange.lower()}_stock_data_{datestamp}.pkl', 'wb') as file:\n",
    "        pickle.dump(stock_data, file)\n",
    "\n",
    "    with open(f'../data/all_{exchange.lower()}_stock_data_{datestamp}_failed.pkl', 'wb') as file:\n",
    "        pickle.dump(failed, file)\n",
    "\n",
    "    return stock_data, failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Working on HON.L - f[0], s[0]\n",
      "2 Working on AIR3.L - f[0], s[0]\n",
      "3 Working on FB1.L - f[0], s[0]\n",
      "4 Working on 2UKS.L - f[0], s[0]\n",
      "AIR3.L FAILED\n",
      "5 Working on MRNS.L - f[1], s[0]\n",
      "FB1.L FAILED\n",
      "6 Working on EMUM.L - f[2], s[0]\n",
      "2UKS.L FAILED\n",
      "7 Working on 72HN.L - f[3], s[0]\n",
      "EMUM.L FAILED\n",
      "8 Working on PMGZ.L - f[4], s[0]\n",
      "MRNS.L FAILED\n",
      "9 Working on MNDI.L - f[5], s[0]\n",
      "72HN.L FAILED\n",
      "10 Working on 0VOU.L - f[6], s[0]\n",
      "PMGZ.L FAILED0VOU.L FAILED\n",
      "11 Working on PRES.L - f[7], s[0]\n",
      "\n",
      "12 Working on IUG.L - f[8], s[0]\n",
      "IUG.L FAILED\n",
      "13 Working on ITH.L - f[9], s[0]\n",
      "ITH.L FAILED\n",
      "14 Working on SENS.L - f[10], s[0]\n",
      "HON.L FAILED\n",
      "15 Working on IQG.L - f[11], s[0]\n",
      "SENS.L FAILED\n",
      "16 Working on FEML.L - f[12], s[0]\n",
      "FEML.L FAILED\n",
      "17 Working on 5QQE.L - f[13], s[0]\n",
      "5QQE.L FAILED\n",
      "18 Working on 0RHR.L - f[14], s[0]\n",
      "0RHR.L FAILED\n",
      "19 Working on SFBE.L - f[15], s[0]\n",
      "SFBE.L FAILED\n",
      "20 Working on 3LBA.L - f[16], s[0]\n",
      "3LBA.L FAILED\n",
      "21 Working on CCPE.L - f[17], s[0]\n",
      "CCPE.L FAILED\n",
      "22 Working on 0QL7.L - f[18], s[0]\n",
      "0QL7.L FAILED\n",
      "23 Working on JARJ.L - f[19], s[0]\n",
      "MNDI.L SUCCESS\n",
      "24 Working on 3STL.L - f[19], s[1]\n",
      "JARJ.L FAILED\n",
      "25 Working on 0QQV.L - f[20], s[1]\n",
      "3STL.L FAILED\n",
      "26 Working on NBI.L - f[21], s[1]\n",
      "0QQV.L FAILED\n",
      "27 Working on KDNC.L - f[22], s[1]\n",
      "PRES.L SUCCESS\n",
      "28 Working on KAPE.L - f[22], s[2]\n",
      "IQG.L SUCCESS\n",
      "29 Working on 0QRA.L - f[22], s[3]\n",
      "NBI.L FAILED\n",
      "30 Working on IEFS.L - f[23], s[3]\n",
      "0QRA.L FAILED\n",
      "31 Working on 0JPO.L - f[24], s[3]\n",
      "IEFS.L FAILED\n",
      "32 Working on PLT3.L - f[25], s[3]\n",
      "0JPO.L FAILED\n",
      "33 Working on 0QM5.L - f[26], s[3]\n",
      "PLT3.L FAILED\n",
      "34 Working on LOAD.L - f[27], s[3]\n",
      "0QM5.L FAILED\n",
      "35 Working on 0URM.L - f[28], s[3]\n",
      "0URM.L FAILED\n",
      "36 Working on SGLD.L - f[29], s[3]\n",
      "LOAD.L FAILED\n",
      "37 Working on MGGT.L - f[30], s[3]\n",
      "KDNC.L SUCCESS\n",
      "38 Working on NUM.L - f[30], s[4]\n",
      "KAPE.L SUCCESS\n",
      "39 Working on SUKC.L - f[30], s[5]\n",
      "SUKC.L FAILED\n",
      "40 Working on 3LDE.L - f[31], s[5]\n",
      "3LDE.L FAILED\n",
      "41 Working on XLF3.L - f[32], s[5]\n",
      "MGGT.L FAILED\n",
      "42 Working on MU2.L - f[33], s[5]\n",
      "SGLD.L FAILED\n",
      "43 Working on 0QMC.L - f[34], s[5]\n",
      "XLF3.L FAILED\n",
      "44 Working on NXT.L - f[35], s[5]\n",
      "MU2.L FAILED\n",
      "45 Working on SKYY.L - f[36], s[5]\n",
      "0QMC.L FAILED\n",
      "46 Working on PTY.L - f[37], s[5]\n",
      "SKYY.L FAILED\n",
      "47 Working on BIFF.L - f[38], s[5]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m stock_data, failed \u001b[39m=\u001b[39m get_exchange_data(\u001b[39m'\u001b[39;49m\u001b[39mLSE\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[6], line 45\u001b[0m, in \u001b[0;36mget_exchange_data\u001b[0;34m(exchange)\u001b[0m\n\u001b[1;32m     42\u001b[0m     name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mThread_\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(x)\n\u001b[1;32m     43\u001b[0m     t \u001b[39m=\u001b[39m threading\u001b[39m.\u001b[39mThread(name\u001b[39m=\u001b[39mname,target\u001b[39m=\u001b[39mworker, daemon\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\u001b[39m.\u001b[39mstart()\n\u001b[0;32m---> 45\u001b[0m symbol_queue\u001b[39m.\u001b[39;49mjoin()\n\u001b[1;32m     47\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(failed))\n\u001b[1;32m     48\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(stock_data))\n",
      "File \u001b[0;32m/usr/lib/python3.10/queue.py:90\u001b[0m, in \u001b[0;36mQueue.join\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mall_tasks_done:\n\u001b[1;32m     89\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munfinished_tasks:\n\u001b[0;32m---> 90\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mall_tasks_done\u001b[39m.\u001b[39;49mwait()\n",
      "File \u001b[0;32m/usr/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    321\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BIFF.L SUCCESS\n",
      "48 Working on MCRO.L - f[38], s[6]\n",
      "NUM.L SUCCESS\n",
      "49 Working on RBD.L - f[38], s[7]\n"
     ]
    }
   ],
   "source": [
    "stock_data, failed = get_exchange_data('LSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exchanges = [\"NYSE\", \"LSE\"]\n",
    "\n",
    "for exchange in exchanges:\n",
    "\n",
    "    exchange_companies = all_companies[(all_companies.exchangeShortName == exchange)]\n",
    "    exchange_stocks = exchange_companies[(exchange_companies.type == 'stock')].reset_index().drop(['exchange', 'exchangeShortName', 'type', 'price'], axis=1)\n",
    "\n",
    "    stock_data = {}\n",
    "    failed = []\n",
    "\n",
    "    symbol_queue = queue.Queue()\n",
    "    [symbol_queue.put(s) for s in exchange_stocks.symbol.tolist()]\n",
    "    symbol_queue.qsize()\n",
    "\n",
    "    def worker():\n",
    "        while True:\n",
    "            symbol = symbol_queue.get()\n",
    "            print(f'Working on {symbol}')\n",
    "\n",
    "            if symbol in stock_data:\n",
    "                print(f\"Already have {symbol}, skipping\")\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                data = fa_utils.get_ticker_data(symbol, api_key)\n",
    "                stock_data[symbol] = data\n",
    "                print(f\"{symbol} SUCCESS\")\n",
    "            except:\n",
    "                print(f\"{symbol} FAILED\")\n",
    "                failed.append(symbol)\n",
    "\n",
    "            symbol_queue.task_done()\n",
    "\n",
    "    for x in range(4):\n",
    "        name = \"Thread_\" + str(x)\n",
    "        t = threading.Thread(name=name,target=worker, daemon=True).start()\n",
    "\n",
    "    symbol_queue.join()\n",
    "\n",
    "    print(len(failed))\n",
    "    print(len(stock_data))\n",
    "\n",
    "    with open(f'../data/all_{exchange.lower()}_stock_data_{datestamp}.pkl', 'wb') as file:\n",
    "        pickle.dump(stock_data, file)\n",
    "\n",
    "    with open(f'../data/all_{exchange.lower()}_stock_data_{datestamp}_failed.pkl', 'wb') as file:\n",
    "        pickle.dump(failed, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(failed))\n",
    "print(len(stock_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'../data/all_{exchange.lower()}_stock_data_{datestamp}.pkl', 'wb') as file:\n",
    "    pickle.dump(stock_data, file)\n",
    "\n",
    "with open(f'../data/all_{exchange.lower()}_stock_data_{datestamp}_failed.pkl', 'wb') as file:\n",
    "    pickle.dump(failed, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'../data/all_{exchange.lower()}_stock_data_{datestamp}.pkl', 'rb') as file:\n",
    "    stock_data_2 = pickle.load(file)\n",
    "\n",
    "print(len(stock_data_2))\n",
    "display(stock_data_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fintech-nb-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "161bb323b90e11c9899af7be07b4c380a7c03bf0e17e1ed36618bfcb5c83301d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
