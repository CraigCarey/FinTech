{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from urllib.request import urlopen\n",
    "import certifi\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import json\n",
    "import queue\n",
    "import threading\n",
    "\n",
    "import fundamentalanalysis as fa\n",
    "import fa_mods as famods\n",
    "import fa_utils\n",
    "\n",
    "with open('/home/craigc/.keys/financialmodelingprep.txt', 'r') as file:\n",
    "    api_key = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies = fa.available_companies(api_key)\n",
    "tradeable_companies = famods.tradable_companies(api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exchanges = all_companies.groupby('exchangeShortName')['exchange'].agg('unique').reset_index().rename(columns={'exchangeShortName': 'short_name', 'unique': 'exhange'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datestamp = datetime.now().strftime('%y%m%d')\n",
    "\n",
    "with open(f'../data/all_symbols_{datestamp}.pkl', 'wb') as file:\n",
    "    pickle.dump(all_companies, file)\n",
    "\n",
    "with open(f'../data/all_tradable_symbols_{datestamp}.pkl', 'wb') as file:\n",
    "    pickle.dump(tradeable_companies, file)\n",
    "\n",
    "with open(f'../data/exchanges_{datestamp}.pkl', 'wb') as file:\n",
    "    pickle.dump(exchanges, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lse_companies = all_companies[(all_companies.exchangeShortName == 'LSE')]\n",
    "nyse_companies = all_companies[(all_companies.exchangeShortName == 'NYSE')]\n",
    "nasdaq_companies = all_companies[(all_companies.exchangeShortName == 'NASDAQ')]\n",
    "\n",
    "lse_stocks = lse_companies[(lse_companies.type == 'stock')].reset_index().drop(['exchange', 'exchangeShortName', 'type', 'price'], axis=1)\n",
    "nyse_stocks = nyse_companies[(nyse_companies.type == 'stock')].reset_index().drop(['exchange', 'exchangeShortName', 'type', 'price'], axis=1)\n",
    "nasdaq_stocks = nasdaq_companies[(nasdaq_companies.type == 'stock')].reset_index().drop(['exchange', 'exchangeShortName', 'type', 'price'], axis=1)\n",
    "\n",
    "print(f\"num LSE companies: {len(lse_companies)}\")\n",
    "print(f\"num LSE stocks: {len(lse_stocks)}\")\n",
    "print()\n",
    "print(f\"num NYSE companies: {len(nyse_companies)}\")\n",
    "print(f\"num NYSE stocks: {len(nyse_stocks)}\")\n",
    "print()\n",
    "print(f\"num NASDAQ companies: {len(nasdaq_companies)}\")\n",
    "print(f\"num NASDAQ stocks: {len(nasdaq_stocks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exchange = \"NASDAQ\"\n",
    "exchange_companies = all_companies[(all_companies.exchangeShortName == exchange)]\n",
    "exchange_stocks = exchange_companies[(exchange_companies.type == 'stock')].reset_index().drop(['exchange', 'exchangeShortName', 'type', 'price'], axis=1)\n",
    "\n",
    "stock_data = {}\n",
    "failed = []\n",
    "\n",
    "symbol_queue = queue.Queue()\n",
    "[symbol_queue.put(s) for s in exchange_stocks.symbol.tolist()]\n",
    "symbol_queue.qsize()\n",
    "\n",
    "def worker():\n",
    "    while True:\n",
    "        symbol = symbol_queue.get()\n",
    "        print(f'Working on {symbol}')\n",
    "\n",
    "        if symbol in stock_data:\n",
    "            print(f\"Already have {symbol}, skipping\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            data = fa_utils.get_ticker_data(symbol, api_key)\n",
    "            stock_data[symbol] = data\n",
    "            print(f\"{symbol} SUCCESS\")\n",
    "        except:\n",
    "            print(f\"{symbol} FAILED\")\n",
    "            failed.append(symbol)\n",
    "\n",
    "        symbol_queue.task_done()\n",
    "\n",
    "for x in range(4):\n",
    "    name = \"Thread_\" + str(x)\n",
    "    t = threading.Thread(name=name,target=worker, daemon=True).start()\n",
    "\n",
    "symbol_queue.join()\n",
    "\n",
    "print(len(failed))\n",
    "print(len(stock_data))\n",
    "\n",
    "with open(f'../data/all_{exchange.lower()}_stock_data_{datestamp}.pkl', 'wb') as file:\n",
    "    pickle.dump(stock_data, file)\n",
    "\n",
    "with open(f'../data/all_{exchange.lower()}_stock_data_{datestamp}_failed.pkl', 'wb') as file:\n",
    "    pickle.dump(failed, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(failed))\n",
    "print(len(stock_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'../data/all_{exchange.lower()}_stock_data_{datestamp}.pkl', 'wb') as file:\n",
    "    pickle.dump(stock_data, file)\n",
    "\n",
    "with open(f'../data/all_{exchange.lower()}_stock_data_{datestamp}_failed.pkl', 'wb') as file:\n",
    "    pickle.dump(failed, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'../data/all_{exchange.lower()}_stock_data_{datestamp}.pkl', 'rb') as file:\n",
    "    stock_data_2 = pickle.load(file)\n",
    "\n",
    "print(len(stock_data_2))\n",
    "display(stock_data_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fintech-nb-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "161bb323b90e11c9899af7be07b4c380a7c03bf0e17e1ed36618bfcb5c83301d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
